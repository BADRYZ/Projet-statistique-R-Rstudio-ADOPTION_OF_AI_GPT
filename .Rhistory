wilcox.test(M$itemf1)
#p value (<5%) H0 rejete , il y a une différence significative du mediane
#(Si les deux cheikhs sont d'accord) on suit le parametrique
#### itemf2 #####
#est quasi normale donc on va faire les 2 test (para et non para )
#test parametrique
t.test(M$itemf2)
#p value (<5%) H0 rejete , il y a une différence significative du  moyenne
#test no parametrique
wilcox.test(M$itemf2)
#p value (<5%) H0 rejete , il y a une différence significative du mediane
#(Si les deux cheikhs sont d'accord) on suit le parametrique
#### itemf3 #####
#est quasi normale donc on va faire les 2 test (para et non para )
#test parametrique
t.test(M$itemf3)
#p value (<5%) H0 rejete , il y a une différence significative du  moyenne
#test no parametrique
wilcox.test(M$itemf3)
#p value (<5%) H0 rejete , il y a une différence significative du mediane
#(Si les deux cheikhs sont d'accord) on suit le parametrique
#### itemf4 #####
#est quasi normale donc on va faire les 2 test (para et non para )
#test parametrique
t.test(M$itemf4)
#p value (<5%) H0 rejete , il y a une différence significative du  moyenne
#test no parametrique
wilcox.test(M$itemf4)
#p value (<5%) H0 rejete , il y a une différence significative du mediane
#(Si les deux cheikhs sont d'accord) on suit le parametrique
#4.2 test de fiabilite de questionnaire
library(Rcmdr)
#Pour itemA
reliability(cov(M[,c("itemA1","itemA2","itemA3","itemA4","itemA5")], use="complete.obs"))
# on alpha comme valeur 0.5512  , on supprime item on constate que lq valeur de alpha diminue
#Pour itemf
reliability(cov(M[,c("itemf1","itemf2","itemf3","itemf4")], use="complete.obs"))
# on alpha comme valeur 0.4968 , on supprime item on constate que lq valeur de alpha diminue
#Pour itemI
reliability(cov(M[,c("itemI1","itemI2","itemI3","itemI4")], use="complete.obs"))
#avec Alpha reliability = 0.6976
#supprimant itemI4
reliability(cov(M[,c("itemI1","itemI2","itemI3")], use="complete.obs"))
#la valeur de alpha passe a 0.7275
#itemI4 exclu
#itemU
reliability(cov(M[,c("itemU1","itemU2","itemU3","itemU4")], use="complete.obs"))
# on alpha comme valeur 0.6086  , on supprime item on constate que lq valeur de alpha diminue
#pour itemUT
reliability(cov(M[,c("itemUT1","itemUT2","itemUT3","itemUT4")], use="complete.obs"))
#avec Alpha reliability = 0.7741
#Supprimer itemUT1
reliability(cov(M[,c("itemUT2","itemUT3","itemUT4")], use="complete.obs"))
#la valeur de alpha passe a 0.7989
#itemUT1 exclu
#4.3 statistique descriptive bivariee
###genre et filiere (quali quali)
chisq.test(table(M$genre,M$filiere))
# p-value = 0.159 >5% Genre n impacte pas filiere
#Confirmant avec boxplot
table(M$genre,M$filiere)
boxplot(M$genre,M$filiere)
#hitogramme
library(Rcmdr)
#quali quali -> histograme
# Création des histogrammes des variables 'filiere' et 'genre'
x <- hist(M$filiere, freq = TRUE, breaks = "Sturges", col = "royalblue1", main = "Histogramme de la variable 'filiere'")
y <- hist(M$genre, freq = TRUE, breaks = "Sturges", col = "grey", main = "Histogramme de la variable 'genre'")
# Affichage des histogrammes
plot(x, main = "Histogrammes de 'filiere' et 'genre'", col = "royalblue1")
plot(y, add = TRUE, col = "grey")
###filiere et age (quali quanti)
library(BioStatR)
eta2(M$filiere,M$age)
#0.012
#Confirmant avec boxplot
table(M$filiere,M$age)
boxplot(M$filiere,M$age)
# pas de liason  d apres box plot
#hitogramme
library(Rcmdr)
#quali quali -> histograme
# Création des histogrammes des variables 'filiere' et 'age'
x <- hist(M$filiere, freq = TRUE, breaks = "Sturges", col = "royalblue1", main = "Histogramme de la variable 'filiere'")
y <- hist(M$age, freq = TRUE, breaks = "Sturges", col = "grey", main = "Histogramme de la variable 'age'")
# Affichage des histogrammes
plot(x, main = "Histogrammes de 'filiere' et 'age'", col = "royalblue1")
plot(y, add = TRUE, col = "grey")
###genre et age (quali quanti)
library(BioStatR)
chisq.test(M$genre,M$age)
#confirmant avec boxplot
table(M$genre,M$age)
boxplot(M$genre,M$age)
#pas de liason entre genre et age
x <- hist(M$genre, freq = TRUE, breaks = "Sturges", col = "royalblue1", main = "Histogramme de la variable 'genre'")
y <- hist(M$age, freq = TRUE, breaks = "Sturges", col = "grey", main = "Histogramme de la variable 'age'")
# Affichage des histogrammes
plot(x, main = "Histogrammes de 'genre' et 'age'", col = "royalblue1")
plot(y, add = TRUE, col = "grey")
#test d hypothese de Recherche
#HYPOTHESE 1
#Existe il une relation entre la perception des problèmes liés à l'utilisation de la technologie
#et l'adoption de celle-ci par les étudiants?
#H0 : Il n'y a pas de relation entre la perception des problèmes liés à l'utilisation
#de la technologie dans l'enseignement supérieur et l'adoption de la technologie par les étudiants.
#H1 : Les étudiants qui perçoivent moins de problèmes liés à l'utilisation de la technologie dans
#l'enseignement supérieur sont plus susceptibles d'adopter la technologie.
#D apres les test univaries , on a trouve que itemA et itemUT suit la loi normal
#on fait tout d abord le test des variances :
var.test(M$itemA1,M$itemUT2)
#Dans notre cas on P-value = 0.0003088(<0.05),Donc les variances ne diffèrent pas  de manière significative.
#Donc H1 accepte
#### RAPPEL ####
#La statistique de test, généralement appelée F ou ratio de variance,
#est une mesure de la différence entre les variances des échantillons.
#Plus la valeur de F est élevée, plus les variances diffèrent.
#La valeur de p est la probabilité associée à la statistique de test.
#Elle indique la probabilité d'observer une différence aussi extrême que celle observée dans les données
#si les variances réelles étaient identiques. Une valeur de p faible (généralement inférieure à 0,05)
#suggère une différence statistiquement significative entre les variances,
#tandis qu'une valeur de p élevée indique que les variances ne diffèrent pas de manière significative.
#Les degrés de liberté (df) représentent le nombre d'observations moins le nombre de paramètres estimés.
#Dans le cas d'un test de variance, il y aura deux ensembles de degrés de liberté :
#les degrés de liberté du numérateur et les degrés de liberté du dénominateur.
#Le numérateur correspond au nombre
#d'échantillons moins un, et le dénominateur correspond au nombre total d'observations moins le nombre d'échantillons.
#HYPOTHESE 2
#Existe il  une relation entre la reconnaissance de l'utilité de la technologie
#et l'adoption de celle-ci par les étudiants?
#H0 : Il n'y a pas de relation entre la reconnaissance de l'utilité de la technologie dans
#l'enseignement supérieur et l'adoption de la technologie par les étudiants.
#H1 : Les étudiants qui reconnaissent l'utilité de la technologie dans l'enseignement
#supérieur sont plus susceptibles d'adopter la technologie.
#D apres les test univaries , on a trouve que itemA et itemU suit la loi normal
#on fait tout d abord le test des variances :
var.test(M$itemA1,M$itemU1)
#Dans notre cas on P-value = 0.4639(>0.05).H0 accepte
#HYPOTHESE 3
#Existe il une relation entre l'adoption de l'IA GPT dans la pratique d'enseignement et
#le niveau de formation des étudiants
#H0 : Il n'existe aucune relation entre l'adoption de l'IA GPT dans la pratique
#d'enseignement et le niveau de formation des étudiants.
#H1 : Il existe une relation entre l'adoption de l'IA GPT
#dans la pratique d'enseignement et le niveau de formation des étudiants.
#D apres les test univaries , on a trouve que itemA et itemF suit la loi normal
#on fait tout d abord le test des variances :
var.test(M$itemA1,M$itemf4)
#Dans notre cas on P-value = 0.007185(<0.05),H1 accepte
#4.4 : Modele statistique
#4.4.1 : Regression simple
#Conditions :
####    A  ###
#1.X et Y quantitative
#x : itemA1
#Y : itemf1
#2. X et Y correle
cor.test(M$itemA1,M$itemf1)
#p-value=0.8339 >5%, il n y a pas de correlation
RegModel.1 <- lm(itemA1~itemf1, data=M)
summary(RegModel.1)
plot(RegModel.1)
#x : itemA2
#Y : itemf2
#2. X et Y correle
cor.test(M$itemA2,M$itemf2)
#p-value=0.2846 , il y a une correlation
#3. Deja on verifie que X et Y suit loi normal
#4. a!=0 et b!=0
#5. erreur -> 0
RegModel.2 <- lm(itemA2~itemf2, data=M)
summary(RegModel.2)
plot(RegModel.2)
#1.X et Y quantitative
#x : itemA3
#Y : itemf3
#2. X et Y correle
cor.test(M$itemA3,M$itemf3)
#p-value=0.6446 , il  y pas a de correlation
#3. Deja on verifie que X et Y suit loi normal
#4. a!=0 et b!=0
#5. erreur -> 0
RegModel.3 <- lm(itemA3~itemf3, data=M)
summary(RegModel.3)
plot(RegModel.3)
#xi : itemAi
#Y : itemf1
#2. Xi et Y correle
cor(M[,c("itemA1","itemA2","itemA3","itemA4","itemA5","itemf1")],
method="spearman", use="complete")
# il y a une correlation
#3. Deja on verifie que X et Y suit loi normal
#4. a!=0 et b!=0
#5. erreur -> 0
RegModel.4 <- lm(itemf1~itemA1+itemA2+itemA3+itemA4+itemA5, data=M)
summary(RegModel.4)
plot(RegModel.4)
#Y : itemf2
#2. Xi et Y correle
cor(M[,c("itemA1","itemA2","itemA3","itemA4","itemA5","itemf2")],
method="spearman", use="complete")
# il y a pas   correlation
RegModel.5 <- lm(itemf2~itemA1+itemA2+itemA3+itemA4+itemA5, data=M)
summary(RegModel.5)
plot(RegModel.5)
#xi : itemAi
#Y : itemf3
#2. Xi et Y correle
cor(M[,c("itemA1","itemA2","itemA3","itemA4","itemA5","itemf3")],
method="spearman", use="complete")
#il y a une correlation
#3. Deja on verifie que X et Y suit loi normal
#4. a!=0 et b!=0
#5. erreur -> 0
RegModel.6 <- lm(itemf3~itemA1+itemA2+itemA3+itemA4+itemA5, data=M)
summary(RegModel.6)
plot(RegModel.6)
#Y : itemf4
#2. Xi et Y correle
cor(M[,c("itemA1","itemA2","itemA3","itemA4","itemA5","itemf4")],
method="spearman", use="complete")
#p-value=0.6446 , il y a une correlation
#3. Deja on verifie que X et Y suit loi normal
#4. a!=0 et b!=0
#5. erreur -> 0
RegModel.7 <- lm(itemf4~itemA1+itemA2+itemA3+itemA4+itemA5, data=M)
summary(RegModel.7)
plot(RegModel.7)
#Pour Adoption
library(Rcmdr)
.cluster <-  KMeans(model.matrix(~-1 + itemA1 + itemA2 + itemA3 + itemA4 +itemA5, M), centers = 2, iter.max = 10, num.seeds = 10)
.cluster$size # Cluster Sizes
.cluster$centers # Cluster Centroids
.cluster$withinss # Within Cluster Sum of Squares
.cluster$tot.withinss # Total Within Sum of Squares
.cluster$betweenss # Between Cluster Sum of Squares
biplot(princomp(model.matrix(~-1 + itemA1 + itemA2 + itemA3 + itemA4 +itemA5, M)), xlabs = as.character(.cluster$cluster))
remove(.cluster)
#Pour factor
library(Rcmdr)
.cluster <-  KMeans(model.matrix(~-1 + itemf1 + itemf2 + itemf3 + itemf4,
M), centers = 2, iter.max = 10, num.seeds = 10)
.cluster$size # Cluster Sizes
.cluster$centers # Cluster Centroids
.cluster$withinss # Within Cluster Sum of Squares
.cluster$tot.withinss # Total Within Sum of Squares
.cluster$betweenss # Between Cluster Sum of Squares
biplot(princomp(model.matrix(~-1 + itemf1 + itemf2 + itemf3 + itemf4, M)),
xlabs = as.character(.cluster$cluster))
remove(.cluster)
#Pour adoption et factor
library(Rcmdr)
.cluster <-  KMeans(model.matrix(~-1 + itemA1 + itemA2 + itemA3 + itemA4 +
itemA5 + itemf1 + itemf2 + itemf3 + itemf4, M), centers = 2, iter.max = 10,
num.seeds = 10)
.cluster$size # Cluster Sizes
.cluster$centers # Cluster Centroids
.cluster$withinss # Within Cluster Sum of Squares
.cluster$tot.withinss # Total Within Sum of Squares
.cluster$betweenss # Between Cluster Sum of Squares
biplot(princomp(model.matrix(~-1 + itemA1 + itemA2 + itemA3 + itemA4 +
itemA5 + itemf1 + itemf2 + itemf3 + itemf4, M)), xlabs =
as.character(.cluster$cluster))
remove(.cluster)
######## FIN DE CODE ########
#######Merci de votre encadrement ######
### genre ####
shapiro.test(M$genre)
shapiro.test(M$age)
library(moments)
kurtosis(M$age)
skewness(M$age)
#Etape4:traitement
#4.1 statistique descriptive univariee
#4.1.1 : Numerique
summary(M)
plot(M$age)
hist(M$itemA1)
hist(M$itemA2)
hist(M$itemA3)
#TEST DE PROPORTIONALITE :
#68 sample , 265 population #hd
prop.test(68,265)
hist(M$itemf1)
hist(M$itemf2)
hist(M$itemf3)
hist(M$itemf4)
### genre ####
shapiro.test(M$genre)
library(moments)
kurtosis(M$genre)
skewness(M$genre)
#TEST DE PROPORTIONALITE :
#68 sample , 265 population #hd
prop.test(68,265)
summary(M)
#Etape4:traitement
#4.1 statistique descriptive univariee
#4.1.1 : Numerique
summary(M)
plot(M$age)
### genre ####
shapiro.test(M$genre)
library(moments)
kurtosis(M$genre)
skewness(M$genre)
### age ####
shapiro.test(M$age)
#p-value 5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$age)
skewness(M$age)
#DONC kurtosis et skewness hors [-3,3] , signifine pas de quasi normalite (test non parametrique  )
### filiere ####
shapiro.test(M$filiere)
#p-value 5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$filiere)
skewness(M$filiere)
#DONC kurtosis et skewness entre [-3,3] , signifine on la quasi normalite (test param et non param)
#######  itemA1  #####
shapiro.test(M$itemA1)
#p-value p-value = 6.975e-10    5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$itemA1)
skewness(M$itemA1)
hist(M$itemA1)
#DONC  ne suit pas la loi normale (test non parametrique)
#######  itemA2
shapiro.test(M$itemA2)
#p-value p-value = 3.268e-10   5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$itemA2)
skewness(M$itemA2)
hist(M$itemA2)
#DONC  ne suit pas la loi normale (test non parametrique)
####### itemA3 #####
shapiro.test(M$itemA3)
#p-value p-value = 2.095e-09    5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$itemA3)
skewness(M$itemA3)
#DONC kurtosis et skewness entre [-3,3] , signifine on la quasi normalite (test param et non param)
###### itemA4
shapiro.test(M$itemA4)
#p-value p-value = 4.615e-10   5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$itemA4)
skewness(M$itemA4)
hist(M$itemA4)
#DONC  ne suit pas la loi normale (test non parametrique)
###### itemA5
shapiro.test(M$itemA5)
#p-value p-value = 1.488e-08    5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$itemA5)
skewness(M$itemA5)
hist(M$itemA5)
#DONC   suit  la loi normale (test  parametrique)
##### itemI1###
shapiro.test(M$itemI1)
#p-value p-value = 3.871e-09    5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$itemI1)
skewness(M$itemI1)
hist(M$itemI1)
#DONC  ne  suit pas la loi normale (test non parametrique)
#### itemI2###
shapiro.test(M$itemI2)
#p-value p-value = 1.618e-09    5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$itemI2)
skewness(M$itemI2)
#DONC kurtosis et skewness entre [-3,3] , signifine on la quasi normalite (test param et non param)
##### itemI3 ###
shapiro.test(M$itemI3)
#p-value p-value = 1.994e-09    5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$itemI3)
skewness(M$itemI3)
#DONC kurtosis et skewness entre [-3,3] , signifine on la quasi normalite (test param et non param)
##### itemI4##
shapiro.test(M$itemI4)
#p-value p-value = 7.249e-07    5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$itemI4)
skewness(M$itemI4)
hist(M$itemI4)
#donc suit loi normal (test parametrique )
#### itemUT1 ###
shapiro.test(M$itemUT1)
#p-value p-value = 6.159e-09    5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$itemUT1)
skewness(M$itemUT1)
#DONC kurtosis et skewness entre [-3,3] , signifine on la quasi normalite (test param et non param)
##### itemUT2 ###
shapiro.test(M$itemUT2)
#p-value p-value = 7.39e-07    5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$itemUT2)
skewness(M$itemUT2)
#DONC kurtosis et skewness entre [-3,3] , signifine on la quasi normalite (test param et non param)
####  itemUT3 ###
shapiro.test(M$itemUT3)
#p-value p-value = 1.582e-08   5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$itemUT3)
skewness(M$itemUT3)
#DONC kurtosis et skewness entre [-3,3] , signifine on la quasi normalite (test param et non param)
##### itemUT4 ##
shapiro.test(M$itemUT4)
#p-value p-value = 2.408e-06   5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$itemUT4)
skewness(M$itemUT4)
hist(M$itemUT4)
#donc suit loi normal (test parametrique)
#### itemU1 ###
shapiro.test(M$itemU1)
#p-value p-value = 1.443e-09   5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$itemU1)
skewness(M$itemU1)
#DONC kurtosis et skewness entre [-3,3] , signifine on la quasi normalite (test param et non param)
##### itemU2 ##
shapiro.test(M$itemU2)
#p-value p-value = 7.188e-10   5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$itemU2)
skewness(M$itemU2)
hist(M$itemU2)
#donc suit loi normal (test parametrique)
####  itemU3 ###
shapiro.test(M$itemU3)
#p-value p-value = 1.359e-08   5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$itemU3)
skewness(M$itemU3)
hist(M$itemU3)
#donc suit loi normal (test parametrique)
###  itemU4 ##
shapiro.test(M$itemU4)
#p-value p-value = 9.505e-09  5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$itemU4)
skewness(M$itemU4)
hist(M$itemU4)
#donc suit loi normal (test parametrique)
##### itemf1 ###
shapiro.test(M$itemf1)
#p-value p-value = 1.519e-07   5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$itemf1)
skewness(M$itemf1)
#DONC kurtosis et skewness entre [-3,3] , signifine on la quasi normalite (test param et non param)
### itemf2 ###
shapiro.test(M$itemf2)
#p-value p-value = 1.122e-08   5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$itemf1)
skewness(M$itemf1)
#DONC kurtosis et skewness entre [-3,3] , signifine on la quasi normalite (test param et non param)
#### itemf3
shapiro.test(M$itemf3)
#p-value p-value = 5.242e-09   5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$itemf3)
skewness(M$itemf3)
hist(M$itemf3)
#donc suit loi normal (test parametrique)
#### itemf4
shapiro.test(M$itemf4)
#p-value p-value = 4.813e-07   5<% -> H1 accepte , Il y a diiference significatif entre la loi normal et la distribution
#Donc on verifie la quasi normalite
library(moments)
kurtosis(M$itemf4)
skewness(M$itemf4)
#DONC kurtosis et skewness hors [-3,3] , signifine on a pass  la quasi normalite (test  non param)
#Etape4:traitement
#4.1 statistique descriptive univariee
#4.1.1 : Numerique
summary(M)
#age (quanti) ->plot
plot(M$age)
#items (quali) -> hist
hist(M$itemA1)
#TEST DE PROPORTIONALITE :
#68 sample , 265 population #hd
prop.test(68,265)
